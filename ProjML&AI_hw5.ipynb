{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/keran-w/Projects-in-ML-and-AI/blob/main/ProjML%26AI_hw5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Homework 5 -- CNNs, AEs, GANs\n",
        "https://submitty.cs.rpi.edu/courses/f22/csci4962/course_material/Homeworks/Homework%205.pdf"
      ],
      "metadata": {
        "id": "inAYxHMoPblj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1mwuCOhgPTlD"
      },
      "outputs": [],
      "source": [
        "# connect to google drive\n",
        "from google.colab import drive\n",
        "from IPython.display import clear_output\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "clear_output()\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !kaggle datasets download -d muratkokludataset/rice-image-dataset"
      ],
      "metadata": {
        "id": "rHGoXcu-avon"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set a fixed randomness\n",
        "import os\n",
        "import torch\n",
        "import random   \n",
        "import numpy as np\n",
        "def seed_everything(seed=20):\n",
        "    \"\"\"set seed for all\"\"\"\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "seed_everything()"
      ],
      "metadata": {
        "id": "kRfStqUrP2he"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import dataset from kaggle\n",
        "if not os.path.isfile('~/.kaggle/kaggle.json'):\n",
        "    os.system('mkdir ~/.kaggle')\n",
        "    os.system('cp /content/drive/MyDrive/kaggle.json ~/.kaggle/kaggle.json')\n",
        "\n",
        "!kaggle datasets download -d misrakahmed/vegetable-image-dataset\n",
        "!unzip vegetable-image-dataset.zip -d .\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "pSn8B7CuPza8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data preprocessing\n",
        "import torchvision\n",
        "\n",
        "train_dir = 'Vegetable Images/train'\n",
        "valid_dir = 'Vegetable Images/validation'\n",
        "test_dir = 'Vegetable Images/test'\n",
        "\n",
        "transform = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.Resize((224,224)),\n",
        "    torchvision.transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "train_dataset = torchvision.datasets.ImageFolder(root=train_dir, transform=transform)\n",
        "valid_dataset = torchvision.datasets.ImageFolder(root=valid_dir, transform=transform)\n",
        "test_dataset = torchvision.datasets.ImageFolder(root=test_dir, transform=transform)"
      ],
      "metadata": {
        "id": "z3hbVgBOco5W"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# \n",
        "label_map = {k:v for k,v in enumerate(train_dataset.classes)}\n",
        "num_classes = len(label_map)"
      ],
      "metadata": {
        "id": "KRPcmnWZeWab"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data preprocessing\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "FI5QRTgLQKLU"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a sample batch\n",
        "sample_batch = next(iter(train_loader))\n",
        "print('Batch image shape:', sample_batch[0].shape)\n",
        "print('Batch label shape:', sample_batch[1].shape)"
      ],
      "metadata": {
        "id": "2bnl5tGjltKg",
        "outputId": "2250c7f6-b570-4e43-b8b7-c22237428799",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch image shape: torch.Size([32, 3, 224, 224])\n",
            "Batch label shape: torch.Size([32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build CNN"
      ],
      "metadata": {
        "id": "aOaqMzKRQUYt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define hyperparameters\n",
        "n_epoch = 5\n",
        "learning_rate = 1e-2\n",
        "weight_decay = 1e-3\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "mSVupqbGmpDk"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "\n",
        "def init_cnn(module): \n",
        "    \"\"\"Initialize weights for CNNs.\"\"\"\n",
        "    if type(module) == nn.Linear or type(module) == nn.Conv2d:\n",
        "        nn.init.xavier_uniform_(module.weight)\n",
        "\n",
        "class LeNet(nn.Module):\n",
        "    def __init__(self, num_classes, device):\n",
        "        super().__init__()\n",
        "        self.output = nn.Sequential(\n",
        "            nn.LazyConv2d(6, kernel_size=5, padding=2), \n",
        "            nn.Sigmoid(),\n",
        "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
        "            nn.LazyConv2d(16, kernel_size=5), \n",
        "            nn.Sigmoid(),\n",
        "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
        "            nn.Flatten(),\n",
        "            nn.LazyLinear(120), \n",
        "            nn.Sigmoid(),\n",
        "            nn.LazyLinear(84), \n",
        "            nn.Sigmoid(),\n",
        "            nn.LazyLinear(num_classes)\n",
        "        )\n",
        "        self.device = device\n",
        "        self.to(device)\n",
        "\n",
        "    def forward(self, image):\n",
        "        image = image.to(self.device)\n",
        "        output = self.output(image)\n",
        "        return output\n",
        "\n",
        "\n",
        "model = LeNet(num_classes, device)\n",
        "model(sample_batch[0]).shape"
      ],
      "metadata": {
        "id": "v9C8hun-hAtc",
        "outputId": "b8ed6e2c-69be-41b3-a231-e6bb83b65541",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 15])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)"
      ],
      "metadata": {
        "id": "mmL3Lmfs2ZUY"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.autonotebook import tqdm\n",
        "\n",
        "# Define train step\n",
        "def train_step(batch, model, criterion, optimizer, device):\n",
        "    optimizer.zero_grad()\n",
        "    logits = model(batch[0])\n",
        "    true_labels = batch[1].long().to(device)\n",
        "    loss = criterion(logits, true_labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "# Define valid step\n",
        "def valid_step(batch, model, device):\n",
        "    logits = model(batch, device).detach()\n",
        "    true_labels = batch[1].long().to(device)\n",
        "    acc = (logits.argmax(1) == true_labels).float().mean().item()\n",
        "    return acc\n",
        "\n",
        "# Define runner\n",
        "def runner(train_loader, valid_loader, n_epoch, model, criterion, optimizer, device):\n",
        "    avg_train_loss_list, avg_valid_acc_list = [], []\n",
        "    for epoch in range(n_epoch):\n",
        "        # Initialize epoch metrics\n",
        "        train_loss_list, valid_acc_list = [], []\n",
        "\n",
        "        # Training process\n",
        "        model.train()\n",
        "        for train_batch in tqdm(train_loader):\n",
        "            train_loss = train_step(train_batch, model, criterion, optimizer, device)\n",
        "            train_loss_list.append(train_loss)\n",
        "        avg_train_loss = np.mean(train_loss_list)\n",
        "        avg_train_loss_list.append(avg_train_loss)\n",
        "\n",
        "        # Validating process\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for valid_batch in tqdm(valid_loader):\n",
        "                valid_acc = valid_step(valid_batch, model, device)\n",
        "                valid_acc_list.append(valid_acc)\n",
        "        avg_valid_acc = np.mean(valid_acc_list)\n",
        "        valid_acc_list.append(avg_valid_acc)\n",
        "    return avg_train_loss_list, avg_valid_acc_list\n",
        "\n",
        "avg_train_loss_list, avg_valid_acc_list = runner(train_loader, valid_loader, n_epoch, model, criterion, optimizer, device)\n",
        "print('Last epoch metrics:', avg_train_loss_list[-1], avg_valid_acc_list[-1])\n"
      ],
      "metadata": {
        "id": "IoMB_q6Vnwza"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}