{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/keran-w/Projects-in-ML-and-AI/blob/main/ProjML%26AI_HW6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Homework 6\n",
        "\n",
        "This homework is the last homework of the semester and is focused on reinforcement\n",
        "learning (RL) "
      ],
      "metadata": {
        "id": "VaPlbT7pyTiv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 1(50 points): \n",
        "\n",
        "We discussed how we can formulate RL problems as an MDP. Describe any\n",
        "real-world application that can be formulated as an MDP. Describe the state space, action\n",
        "space, transition model, and rewards for that problem. You do not need to be precise in the\n",
        "description of the transition model and reward (no formula is needed). Qualitative description\n",
        "is enough.\n"
      ],
      "metadata": {
        "id": "UjBEKzjByfsv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### An RL applications to healthcare\n",
        "\n",
        "Application: Sepsis (severe infections with organ failure) treatment\n",
        "\n",
        "State space: A patient’s physiological state at a point in time as a continuous vector (using physiological data from the ICU)\n",
        "\n",
        "Action space: intravenous fluid dose (0,1,2,3,4) and vasopressor dose (0,1,2,3,4)\n",
        "\n",
        "Transition model: transitions are sampled from the training set with probability proportional to the previous error\n",
        "\n",
        "Reward function: A patient's overall health level, evaluated by SOFA score (measuring organ failure) and the\n",
        "patient’s lactate levels (measure of cell-hypoxia that is higher in septic patients)"
      ],
      "metadata": {
        "id": "kPFJUzTX_a19"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reference:\n",
        "\n",
        "[1] Raghu A, Komorowski M, Ahmed I, Celi L, Szolovits P, Ghassemi M. Deep reinforcement learning for sepsis treatment. arXiv preprint arXiv:1711.09602. 2017 Nov 27. https://arxiv.org/pdf/1711.09602.pdf\n",
        "\n",
        "[2] Isaac G. A review of recent reinforcement learning applications to healthcare https://towardsdatascience.com/a-review-of-recent-reinforcment-learning-applications-to-healthcare-1f8357600407"
      ],
      "metadata": {
        "id": "B1kLNypf-91V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Task 2(50 points): \n",
        "RL is used in various sectors - Healthcare, recommender systems and trading\n",
        "are a few of those. Pick one of the three areas. Explain one of the problems in any of these\n",
        "domains that can be more effectively solved by reinforcement learning. Find an open-source\n",
        "project (if any) that has addressed this problem. Explain this project in detail."
      ],
      "metadata": {
        "id": "LFLNj8WKyorv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Area: healthcare\n",
        "\n",
        "Problem: healthcare prediction problems should be personalized, instead of analysis on big data. However, with few patient's prior infomation, the prediction lacks credibility.\n",
        "\n",
        "Project: Blood Glucose Level Prediction\n",
        "https://github.com/jxx123/simglucose\n",
        "\n",
        "Explanation: Using reinforcement learning would solve this problem. Instead of tracing the entire history, we can build a Markov decision process, and prediction would consider only a precious state. Even though the history is insufficient, we could still simulate the patient's state-to-state conditions.\n"
      ],
      "metadata": {
        "id": "PW1Btil62NL1"
      }
    }
  ]
}